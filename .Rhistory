# Feature Importance plot
varImpPlot(forest_modl)
View(df)
summary(lm(aramaic~early_date, df))
summary(lm(early_date~aramaic, df))
summary(glm(early_date~aramaic, df))
summary(glm(aramaic~early_date, df))
summary(glm(aramaic~as.numeric(early_date), df))
summary(glm(aramaic~as.numeric(early_date), df, family = "binomial"))
#plot logistic regression curve
plot(vs ~ hp, data=mtcars, col="steelblue")
lines(vs ~ hp, newdata, lwd=2)
plot(aramaic~as.numeric(early_date)p, data=df, col="steelblue")
plot(aramaic~as.numeric(early_date), data=df, col="steelblue")
plot(aramaic~as.numeric(early_date), data=df)
lines(aramaic~as.numeric(early_date), df, lwd=2)
plot(aramaic~as.numeric(early_date), data=df)
library(ggplot2)
#plot logistic regression curve
ggplot(df, aes(x=early_date, y=aramaic)) +
geom_point(alpha=.5) +
stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial))
summary(lm(aramaic~period, df))
summary(lm(aramaic~as.factor(period), df))
df$period
unique(df$period)
unique(df$region)
summary(lm(aramaic~as.factor(region), df))
summary(lm(as.factor(aramaic)~region, df))
summary(lm(as.factor(aramaic)~as.factor(region), df))
summary(lm(aramaic~as.factor(region), df))
summary(lm(as.numeric(aramaic)~as.factor(region), df))
summary(lm_modl = lm(as.numeric(aramaic)~as.factor(region), df))
summary(lm_modl -> lm(as.numeric(aramaic)~as.factor(region), df))
region_lm_modl = lm(as.numeric(aramaic)~as.factor(region), df))
region_lm_modl = lm(as.numeric(aramaic)~as.factor(region), df)
summary(region_lm_modl)
region_lm_modl = glm(as.numeric(aramaic)~as.factor(region), df)
region_lm_modl = glm(as.numeric(aramaic)~as.factor(region), df, family="binomial")
region_lm_modl = glm(aramaic~as.factor(region), df, family="binomial")
summary(region_lm_modl)
plot(aramaic~as.factor(region), data=df, col="steelblue")
plot(aramaic~as.factor(region), data=df)
region_lm_modl = glm(aramaic~as.factor(region)+period, df, family="binomial")
summary(region_lm_modl)
region_lm_modl = glm(aramaic~as.factor(region), df, family="binomial")
summary(region_lm_modl)
region_lm_modl = glm(aramaic~as.factor(region)+early_date, df, family="binomial")
summary(region_lm_modl)
region_lm_modl = glm(aramaic~as.factor(region), df, family="binomial")
summary(region_lm_modl)
region_lm_modl = glm(aramaic~as.factor(region)+geo_place, df, family="binomial")
summary(region_lm_modl)
region_lm_modl = glm(aramaic~as.factor(region)+ms_item, df, family="binomial")
summary(region_lm_modl)
library(tidyverse)
library(randomForest)
library(caret)
setwd("~/Documents/iip-texts")
iip_data = read_csv("manuscript_data.csv")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name)) %>%
na.omit()
# Splitting data into testing and training data sets
n = nrow(df)
test_index = sample.int(n, size=round(.2*n))
df_train = df[-test_index,]
df_test = df[test_index,]
# Creating a general formula for models
formula = as.formula(aramaic~.)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 500, mtry = 3)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
# Feature Importance table
importance(forest_modl)
# Feature Importance plot
varImpPlot(forest_modl)
region_lm_modl = glm(aramaic~as.factor(region)+ms_item, df, family="binomial")
summary(region_lm_modl)
region_lm_modl = glm(aramaic~as.factor(region)+early_date, df, family="binomial")
summary(region_lm_modl)
region_lm_modl = glm(aramaic~as.factor(region), df, family="binomial")
summary(region_lm_modl)
plot(aramaic~as.factor(region), data=df)
lines(vs ~ hp, newdata, lwd=2)
plot(aramaic~as.factor(region), data=df)
region_lm_modl = glm(aramaic~as.factor(region)+period, df, family="binomial")
summary(region_lm_modl)
plot(aramaic~as.factor(period), data=df)
library(tidyverse)
library(randomForest)
library(caret)
setwd("~/Documents/iip-texts")
iip_data = read_csv("manuscript_data.csv")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name)) %>%
na.omit()
# Splitting data into testing and training data sets
n = nrow(df)
test_index = sample.int(n, size=round(.6*n))
df_train = df[-test_index,]
df_test = df[test_index,]
# Creating a general formula for models
formula = as.formula(aramaic~.)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 500, mtry = 3)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
# Feature Importance table
importance(forest_modl)
# Feature Importance plot
varImpPlot(forest_modl)
library(tidyverse)
library(randomForest)
library(caret)
setwd("~/Documents/iip-texts")
iip_data = read_csv("manuscript_data.csv")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name)) %>%
na.omit()
# Splitting data into testing and training data sets
n = nrow(df)
test_index = sample.int(n, size=round(.6*n))
df_train = df[-test_index,]
df_test = df[test_index,]
# Creating a general formula for models
formula = as.formula(aramaic~.)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 500, mtry = 3)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
library(tidyverse)
library(randomForest)
library(caret)
setwd("~/Documents/iip-texts")
iip_data = read_csv("manuscript_data.csv")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name)) %>%
na.omit()
# Splitting data into testing and training data sets
n = nrow(df)
test_index = sample.int(n, size=round(.5*n))
df_train = df[-test_index,]
df_test = df[test_index,]
# Creating a general formula for models
formula = as.formula(aramaic~.)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 500, mtry = 3)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
library(tidyverse)
library(randomForest)
library(caret)
setwd("~/Documents/iip-texts")
iip_data = read_csv("manuscript_data.csv")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name)) %>%
na.omit()
# Splitting data into testing and training data sets
n = nrow(df)
test_index = sample.int(n, size=round(.6*n))
df_train = df[-test_index,]
df_test = df[test_index,]
# Creating a general formula for models
formula = as.formula(aramaic~.)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 500, mtry = 3)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
# Feature Importance table
importance(forest_modl)
# Feature Importance plot
varImpPlot(forest_modl)
region_lm_modl = glm(aramaic~region, df, family="binomial")
summary(region_lm_modl)
plot(aramaic~as.factor(period), data=df)
plot(aramaic~region, data=df)
plot(aramaic~region, data=df)
region_lm_modl$residuals
qqplot(region_lm_modl$residuals)
qqplot(region_lm_modl$residuals, region_lm_modl$fitted.values)
plotregion_lm_modl$fitted.values)
plot(region_lm_modl$fitted.values)
plot(model, which = 4, id.n = 3)
plot(region_lm_modl, which = 4, id.n = 3)
table(df$region)
table(df$period)
library(tidyverse)
library(randomForest)
library(caret)
setwd("~/Documents/iip-texts")
iip_data = read_csv("manuscript_data.csv")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name)) %>%
na.omit()
# Splitting data into testing and training data sets
n = nrow(df)
test_index = sample.int(n, size=round(.6*n))
df_train = df[-test_index,]
df_test = df[test_index,]
# Creating a general formula for models
formula = as.formula(aramaic~.)
iip_data = read_excel("manuscript_data.xlsx")
iip_data = readxl::read_excel("manuscript_data.xlsx")
iip_data = read_csv("manuscript_data.xlsx")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name))
library(tidyverse)
library(randomForest)
library(caret)
setwd("~/Documents/iip-texts")
iip_data = read_csv("manuscript_data.xlsx")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name))
View(iip_data)
library(tidyverse)
library(randomForest)
library(caret)
setwd("~/Documents/iip-texts")
iip_data = read_csv("manuscript_data.csv")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name))
# Splitting data into testing and training data sets
n = nrow(df)
test_index = sample.int(n, size=round(.6*n))
df_train = df[-test_index,]
df_test = df[test_index,]
# Creating a general formula for models
formula = as.formula(aramaic~.)
table(df$period)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 500, mtry = 3)
View(iip_data)
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name, geo_place)) %>%
na.omit()
library(tidyverse)
library(randomForest)
library(caret)
setwd("~/Documents/iip-texts")
iip_data = read_csv("manuscript_data.csv")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name, geo_place)) %>%
na.omit()
# Splitting data into testing and training data sets
n = nrow(df)
test_index = sample.int(n, size=round(.6*n))
df_train = df[-test_index,]
df_test = df[test_index,]
# Creating a general formula for models
formula = as.formula(aramaic~.)
table(df$period)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 500, mtry = 3)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
library(tidyverse)
library(randomForest)
library(caret)
setwd("~/Documents/iip-texts")
iip_data = read_csv("manuscript_data.csv")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name, geo_place)) %>%
na.omit()
# Splitting data into testing and training data sets
n = nrow(df)
test_index = sample.int(n, size=round(.2*n))
df_train = df[-test_index,]
df_test = df[test_index,]
# Creating a general formula for models
formula = as.formula(aramaic~.)
table(df$period)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 500, mtry = 3)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
# Feature Importance table
importance(forest_modl)
# Feature Importance plot
varImpPlot(forest_modl)
region_lm_modl = glm(aramaic~region, df, family="binomial")
summary(region_lm_modl)
library(tidyverse)
library(randomForest)
library(caret)
setwd("~/Documents/iip-texts")
iip_data = read_csv("manuscript_data.csv")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name, geo_place)) %>%
filter(period != "Unknown") %>%
na.omit()
# Splitting data into testing and training data sets
n = nrow(df)
test_index = sample.int(n, size=round(.2*n))
df_train = df[-test_index,]
df_test = df[test_index,]
# Creating a general formula for models
formula = as.formula(aramaic~.)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 500, mtry = 3)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
# Feature Importance table
importance(forest_modl)
# Feature Importance plot
varImpPlot(forest_modl)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 500, mtry = 5)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
# Feature Importance table
importance(forest_modl)
# Feature Importance plot
varImpPlot(forest_modl)
region_lm_modl = glm(aramaic~region, df, family="binomial")
summary(region_lm_modl)
unique(df$region)
library(tidyverse)
library(randomForest)
library(caret)
setwd("~/Documents/iip-texts")
iip_data = read_csv("manuscript_data.csv")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name, geo_place)) %>%
filter(region != "Unknown") %>%
na.omit()
# Splitting data into testing and training data sets
n = nrow(df)
test_index = sample.int(n, size=round(.2*n))
df_train = df[-test_index,]
df_test = df[test_index,]
# Creating a general formula for models
formula = as.formula(aramaic~.)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 500, mtry = 5)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
# Feature Importance table
importance(forest_modl)
# Feature Importance plot
varImpPlot(forest_modl)
region_lm_modl = glm(aramaic~region, df, family="binomial")
summary(region_lm_modl)
plot(region_lm_modl, which = 4, id.n = 3)
unique(df$region)
library(tidyverse)
library(randomForest)
library(caret)
setwd("~/Documents/iip-texts")
iip_data = read_csv("manuscript_data.csv")
library(tidyverse)
library(randomForest)
library(caret)
iip_data = read_csv("manuscript_data.csv")
df = iip_data %>%
mutate(aramaic = as.factor(ifelse(main_lang == "arc", 1, 0))) %>%
select(-c(main_lang, name, geo_place)) %>%
filter(region != "Unknown") %>%
na.omit()
# Splitting data into testing and training data sets
n = nrow(df)
test_index = sample.int(n, size=round(.2*n))
df_train = df[-test_index,]
df_test = df[test_index,]
# Creating a general formula for models
formula = as.formula(aramaic~.)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 500, mtry = 5)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
# Feature Importance table
importance(forest_modl)
# Feature Importance plot
varImpPlot(forest_modl)
region_lm_modl = glm(aramaic~region, df, family="binomial")
summary(region_lm_modl)
plot(region_lm_modl, which = 4, id.n = 3)
unique(df$region)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 500, mtry = 3)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 600, mtry = 3)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
# Feature Importance table
importance(forest_modl)
# Feature Importance plot
varImpPlot(forest_modl)
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 600, mtry = 5)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
# Running the forest with 500 tress and 5 tries
forest_modl = randomForest(formula, data = df_train,
ntree = 600, mtry = 3)
forest_modl
# Predicting and testing the accuracy
bag_preds <- predict(forest_modl, df_test)
# Creating the confusion matrix for the test
confusion <- caret::confusionMatrix(as.factor(bag_preds),
as.factor(df_test$aramaic))
confusion
# Feature Importance table
importance(forest_modl)
# Feature Importance plot
varImpPlot(forest_modl)
region_lm_modl = glm(aramaic~region, df, family="binomial")
summary(region_lm_modl)
plot(region_lm_modl, which = 4, id.n = 3)
unique(df$region)
